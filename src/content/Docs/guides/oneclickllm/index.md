---
categories: ["Guides"]
tags: ["Deployment", "API"]
weight: 1
title: "OneClickLLM"
linkTitle: "OneClickLLM"
---

OneClickLLM simplifies the deployment of LLM inference APIs on the Akash Network, allowing users to deploy any open source large language model from Huggingface or Ollama Registry with zero configuration. With the capability to deploy within seconds, users can select a model, generate a properly configured SDL file, and deploy it seamlessly on Cloudmos or the console. The API is compatible with the popular OpenAI library, serving as a drop-in replacement. The fully automated and managed deployment process ensures high availability, scalability, and security, making it easy to deploy your own LLM or use the free demo [API](https://one-click-llm.vercel.app/free-demo-api/example/).

## Free Demo Inference API

OneClickLLM offers a free API endpoint featuring llava-phi3, llama2-7b, and Mistril-7b models. These endpoints allow users to explore and become familiar with the functionalities before deciding to deploy your private LLM inference API. The endpoints are also compatible with the OpenAI library and serve as an open-source drop-in replacement.


### Base Link

You can access the API using the follwing base link: